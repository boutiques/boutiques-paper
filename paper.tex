\documentclass{article}

%%%% Packages %%%%

\usepackage{minted} % Used for JSON highlighting
\usepackage{pdfcomment} % Used for notes and todos
\usepackage[margin=1in]{geometry} % Increases margins
\usepackage[table]{xcolor} % Color definitions
\usepackage{algorithm} % Algorithm float
\usepackage{algpseudocode} % Algorithmic environment
\usepackage{xspace}

%%%% Commands %%%%

\newcommand{\note}[2]{\pdfmargincomment[color=yellow,author=#1,open=true]{#2}}
\newcommand{\todo}[1]{\color{red}TODO: #1\color{black}}
\newcommand{\boutiques}{Boutiques\xspace}
\newcommand{\notimplementedyet}[1]{\color{blue}\emph{#1}\footnote{Still needs to be implemented}\color{black}\xspace}
\algrenewcommand{\algorithmiccomment}[1]{\# \textit{#1}} % so that comments in algorithms are preprended by '#' instead of a small right arrow

\title{Boutiques: a flexible framework for automated application integration in computing platforms}

\begin{document}

\author{Tristan Glatard, Tristan Aumentado-Armstrong, Natacha Beck, Pierre Bellec,\\
        Remi Bernard, Sorina Camarasu-Pop, Fr\'ed\'eric Cervenansky, Samir Das, \\
        Rafael Ferreira da Silva, Guillaume Flandin, John Flavin, Pascal Girard, \\
         Krzysztof J. Gorgolewski, Charles G. Guttmann, Nathaniel Kofalt, Pierre-Olivier Quirion,\\
         Pierre Rioux, Gunnar Schaeffer, Marc-\'Etienne Rousseau, Alan C. Evans}

\maketitle

\abstract{Porting applications to execution platforms such as web
  portals and workflow engines is critical to enable their sharing
  among scientific communities and their efficient execution on
  computing infrastructures. However, application porting remains a
  costly human effort that consists of 1)~installing the application
  on the target infrastructure, 2)~describing the application in a
  format compatible with the execution platform, and 3)~generating
  proper user interfaces. Due to the variety of platforms, application
  porting efforts are often replicated several times while
  mutualization would save cost and improve the quality of the ported
  applications. We describe \boutiques, a system that allows for
  automatic import and exchange of applications across
  platforms. \boutiques adopts a rich, flexible application
  description format and it relies on Linux containers to install
  applications across platforms in a lightweight manner. It is
  currently supported by \todo{X} platforms and was used to describe
  \todo{Y} applications.  }

\section{Introduction}

Platforms such as web services, portals, virtual research
environments, science gateways and workflow engines often rely on
third-party data processing and simulation applications to deliver
services to their users. Such applications are often repeatedly and
manually ported to various platforms whereas this porting effort would
greatly benefit from being mutualized. Meanwhile, virtual container
systems such as Docker and Singularity greatly facilitate the sharing
of software and improve the reproducibility of analyses by defining
immutable, reusable execution environments. However, containers need
to be properly annotated to allow platforms to leverage the software
they contain. Basically, the command lines that can be run in a
container must be formally described so that they can be automatically
created and executed by platforms. Describing command lines is not
straightforward since they often contain implicit semantics specified
in human-readable documents such as manuals.

\boutiques is a system to share command-line applications across
platforms. In \boutiques, a command line is described using a flexible
template comprising the inputs it requires and the outputs it
produces. Inputs may be inter-dependent, e.g., input A cannot be used
if input B is used, and passed in configuration files or directly on
the command line. Such formal descriptions, also called
\emph{manifests}, allow for advanced validation of input values to
prevent errors. Manifests refer to containers where applications and
all their dependencies are installed. \boutiques also provides a
simple parallelization framework that allows applications such as
workflow engines to concurrently execute multiple tasks (in the
remainder, tasks are called \emph{invocations}). A set of core tools
facilitate the construction, validation and execution of \boutiques
manifests. A repository orchestrates these tools together. \boutiques
manifests are intented to be produced by scientific application
developers, to be published in common repositories and to be consumed
by execution platforms.

The remainder of this paper describes the \boutiques system
(Section~\ref{sec:system}) and reports on its adoption by platforms
and applications in the neuroinformatics domain, our primary field of
interest (Section~\ref{sec:results}). It closes on a discussion and
comparison with related systems.

\note{Tristan}{Vocabulary (check consistency across the paper): tool vs. application}
\note{Tristan}{Targeted journals: Scientific Data, Giga Science, Frontiers in Neuroinformatics, Future Generation Computer Systems}

\section{System description}
\label{sec:system}

Applications are described with a JSON manifest that specifies the
command-line template, inputs and outputs. The manifest may point to a
container where the application and all its dependencies are
installed. It may also contain an invocation schema used for input
validation. At runtime, the execution platform builds the command line
from the manifest and values entered by the user. The platform runs
the command line on the execution infrastructure, e.g., a server, a
cluster or a cloud, within a container whenever available. To build
and run the command line, the platform may rely on the \boutiques core
tools, in particular on the validator and local executor. Application
manifests may be stored in the repository which provides additional
features.

\subsection{Command-line description}

The core component of the manifest is a flexible command-line
description represented as a simple string template complying to the
syntax of the \texttt{bash} UNIX shell. \texttt{bash} is the default
shell on the major Linux distributions and OS X. The command-line
template may contain placeholders for input and output values, called
value keys. The command line may actually
encompass several commands separated, e.g., by semicolumns, pipes
(\texttt{|}) or ampersands (\texttt{\&}). Such a flexible command-line
specification is meant to facilitate the embedding of minor mundane
operations on the command line, for instance directory creation, input
decompression or output archival.

Here is an example of a typical command-line template:
\begin{verbatim}
exampleTool_1 [STRING_INPUT] [FILE_INPUT] [ENUM_INPUT] | \
                              exampleTool_2 [FLAG_INPUT] [NUMBER_INPUT] >> [LOG].txt
\end{verbatim}
The template contains six value keys for input and output values, that
will be replaced by values and file names according to the user input
when the application is executed. Flags will also be added wherever
appropriate, with customizable separators. No particular syntax is
imposed for the value keys, they just have to be unique.  Note the use
of the pipe (\texttt{|}) operator to chain applications, and of the
\texttt{>>} operator to redirect the standard output to a file.

\subsection{Input description}

\paragraph{General properties.} Inputs must have a name, a unique
identifier and a type. They may be optional, have a description, a
value key, a flag and flag separator, and a default value. Inputs may
also be ordered lists: in this case, value keys are substituted by the
space-separated list of input values.

\paragraph{Types.} Inputs may be of type \texttt{String},
\texttt{Number}, \texttt{Flag} or \texttt{File}. \texttt{File} may
also represents a directory. Types can be restricted to a specific set
of values (\texttt{String} and \texttt{Number} only), to a specific
range (\texttt{Number} only), to integers or to booleans (\texttt{Number}
only).

\paragraph{Groups and dependencies.} Groups of inputs may be defined
with a identifier, name and list of input identifiers. Groups may be
used to improve the presentation in a graphical user interface and to
specify the following constraints among inputs: (1)
\texttt{mutually-exclusive}: only one input in the group may have a
value; (2) \texttt{one-is-required}: at least one input in the group
must have a value. Dependencies among inputs may also be defined
regardless of a particular group: an input may (1) require a list of
inputs and (2) disable a list of inputs.

Listing~\ref{listing:input-example} shows the definition of an input
in the command line exemplified above. According to this definition
and assuming that the input value entered by the user is 0.3, the
string \texttt{[NUMBER\_INPUT]} will be replaced by \texttt{-n=0.3} on
the command line at execution time.
\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=21pt,
               tabsize=4]{js}
{
    "id" : "num_input",
    "name" : "A number input",
    "type" : "Number",
    "value-key" : "[NUMBER_INPUT]",
    "optional" : true,
    "command-line-flag" : "-n",
    "command-line-separator" : "=",
    "minimum" : 0,
    "maximum" : 1,
    "exclusive-minimum" : true,
    "exclusive-maximum" : false
  }
\end{minted}
\caption{Input example.} 
\label{listing:input-example}
\end{listing}

\subsection{Output description}

Application outputs are files and directories that need to be
transferred and delivered to the user once the execution is
complete. Although it may not be required to distinguish inputs from
outputs to build the application command line, this information is
needed by computing platforms to identify the files that must be saved
after the execution.

In \boutiques, output files must have a unique identifier, a name and
a path template that specifies the file or directory name. Path
templates may include input value keys in case output files are named
after the input values. In this case, input values may be stripped
from specific strings, e.g., file extensions before being substituted
in the path template. Output files may also have a description, a
command-line flag, a flag separator, and a value key in case they
appear on the command line. They may be optional in case the file is
not always produced by the application, for instance when it is
produced only when a particular flag is activated. They may also be
(un-ordered) lists: in this case, the path template must contain a
wildcard (\texttt{*}) matching any string of characters and defining
the pattern used to match the output files in the list.

Listing~\ref{listing:output-example} shows the definition of an output
file in the command line exemplified before. According to this
definition and assuming that the string input value entered by the
user is "foo.csv", the string \texttt{[LOG]} will be
replaced by \texttt{log-foo} on the command line at execution time.

\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=21pt,
               tabsize=4]{js}

{
    "id" : "logfile",
    "name" : "Log file",
    "description" : "The output log file from the example application",
    "path-template" : "log-[STRING_INPUT]",
    "value-key" : "[LOG]",
    "path-template-stripped-extensions" : [".txt", ".csv"],
    "optional" : false
}
\end{minted}
\caption{Output file example} 
\label{listing:output-example}
\end{listing}

\subsection{Configuration files}
\label{sec:configuration-files}
A large number of applications rely on configuration files rather than
command-line options to define their input and output
parameters. Indeed, as the number of parameters increases, command
lines rapidly become long and cumbersome whereas configuration files
allow for better structure and documentation.

Configuration files may be complex though, and specified in any
language.  As it does not seem reasonable to adopt a particular
template for configuration files, the \boutiques specification allows
application developers to specify their own template containing input
and output value keys. Configuration files are specific types of
output files that must have a file template in addition to a path
template that defines how they will be named and where they will be
written. They may also have a value key and a flag in case they need
to be passed on the command
line. Listing~\ref{listing:configuration-file-example} shows an
example.
\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=21pt,
               tabsize=4]{js}
               {
                   "id": "config_file",
                   "name": "Configuration file",
                   "type": "Configuration File",
                   "value-key": "[CONFIG_FILE]",
                   "path-template": "config.txt",
                   "file-template": [
                   "# This input is hard-coded",
                   "stringInput=foo",
                   "fileInput=[FILE-INPUT]",
                   "# And here is the result",
                   "fileOutput=[OUTPUT-FILE]",
                   ""
                   ]
                 }
\end{minted}
\caption{Configuration file example. The file template is defined as
  an array of strings to allow for multi-line strings in JSON.}
\label{listing:configuration-file-example}
\end{listing}

\subsection{Command-line construction}

At runtime, a value is assigned to all the mandatory and some of the
optional inputs. %% Inputs of type ``String'' may contain any string,
%% inputs of type "Number" must contain a string representing a number,
%% inputs of type "File" must contain a string representing a file path
%% (absolute or relative to the execution directory) and inputs of type
%% "Flag" must contain a boolean. 
%% When input is a list, the value contains the concatenation of all the
%%values in the list.
Algorithm~\ref{algo:command-line} shows how the command line is
constructed from the manifest and the values entered by the user. It
substitutes all the value keys in the command line, output path
templates and configuration files, and writes the configuration files.
\begin{algorithm}[h!]
\caption{Command-line construction}
\label{algo:command-line}
\begin{algorithmic}
  \State \Comment{Substitute input value keys in output path templates, configuration files and command line.}
  \For{\texttt{input} in \texttt{inputs}}
  \If{\texttt{input} has a \texttt{value-key}}
  \For{\texttt{output} in \texttt{outputs}}
  \State \texttt{stripped\_value} = \texttt{input\_value}
  \If{\texttt{input} type is \texttt{File}}
  \State In \texttt{stripped\_value}, remove  all elements in \texttt{path-template-stripped-extensions}.
  \EndIf
  \State In \texttt{path-template}, replace all occurrences of \texttt{value-key} by \texttt{stripped\_value}.
  \If{\texttt{output} has a \texttt{file-template}}
  \State In any line of \texttt{file-template}, replace all occurrences of \texttt{value-key} by \texttt{stripped\_value}.
  \EndIf
  \EndFor
  \State Prepend \texttt{command-line-flag} and \texttt{command-line-flag-separator} to \texttt{input\_value}.
  \State In \texttt{command-line}, replace all occurrences of \texttt{value-key} by \texttt{input\_value}.
  \EndIf
  \EndFor

  \State \Comment{Substitute output value keys in configuration files and command line.}
  \For{\texttt{output} in \texttt{outputs}}
  \If{\texttt{output} has a \texttt{value-key}}
  \For{\texttt{output} in \texttt{outputs}}
  \If{\texttt{output} has a \texttt{file-template}}
  \State In any line of \texttt{file-template}, replace all occurrences of \texttt{value-key} by \texttt{path-template}.
  \State \Comment{Input \texttt{value-key} have been substituted in \texttt{path-template} previously.}
  \EndIf
  \EndFor
  \State Prepend \texttt{command-line-flag} and \texttt{command-line-flag-separator} to \texttt{path-template}.
  \State In \texttt{command-line}, replace all occurrences of \texttt{value-key} by \texttt{path-template}.
  \EndIf
  \EndFor

  \State \Comment{Write all configuration files.}
  \For{\texttt{output} in \texttt{outputs}}
  \If{\texttt{output} has a \texttt{file-template}}
  \State Write \texttt{file-template} in \texttt{path-template}
  \State \Comment{Value keys have been substituted in \texttt{file-template} previously.}
  \EndIf
  \EndFor

\end{algorithmic}
\end{algorithm}

\subsection{Invocation schema}
\label{sec:invocation-schema}

Rigorous input validation is an important motivation for
\boutiques. The obvious solution for JSON documents is to rely on an
application-specific JSON schema, called \emph{invocation schema}, to
specify the input values accepted by an application. Platforms can
rely on invocation schemas to validate inputs using
any JSON validator, without having to develop specific code.

Invocation schemas, however, are complex JSON objects. Basically, they
must represent the properties described above in a formal way,
including dependencies between
inputs. Listing~\ref{listing:invocation-schema-example} shows an
example of how dependencies between mutually exclusive parameters are
defined in the invocation schema. As it does not seem realistic to
assume that developers will easily write correct invocations schemas
even for their own applications, invocation schemas can be generated
automatically using a core \boutiques tool. The invocation schema is
stored as an optional property of the Boutiques manifest.

\notimplementedyet{The invocation schema also has a
  \texttt{task-dependencies} array that allows specifying that the new
  invocation may start only when previously-submitted invocations have
  completed. This property is used in the parallelization model
  described hereafter.}

\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=21pt,
               tabsize=4]{js}
"dependencies" : {
      "num_input" : {
         "properties" : {
            "str_input" : {
               "not" : {}
            }
         }
      },
      "str_input" : {
         "properties" : {
            "num_input" : {
               "not" : {}
            }
         }
      }
   }
\end{minted}
\caption{Excerpt from invocation schema showing dependencies between
  two mutually exclusive parameters \texttt{num\_input} and
  \texttt{str\_input}.}
\label{listing:invocation-schema-example}
\end{listing}

\subsection{Parallelization support}
\label{sec:parallelization}
\boutiques supports parallelism by allowing applications to submit new
invocations through the following protocol \todo{Needs to be
  documented on Github}:
\begin{enumerate}
\item Applications write a JSON object complying to the invocation
  schema in their execution directory.
\item The platform reads the JSON object, creates the corresponding
  invocation, and writes back the invocation id in the same directory.
% The platform could also support status requests.
\end{enumerate}
Several invocations can be submitted at once, possibly using the
\texttt{task-dependencies} array to specify dependencies among
them. This mechanism is implemented in the Boutiques schema using a
single property, \texttt{can-submit-tasks}.

Although very simple, this model allows wrapping complete
workflows. Workflows are wrapped as any other application, and they
can be executed using any engine provided that it is installed in the
container image referred in the application manifest. Such a ``task
encapsulation'' model allows for a scalable and reliable execution of
workflows expressed in a variety of languages, as detailed in
~\cite{glatard2016fgcs}.

\subsection{Containers}

Applications are installed in a container image complying to the
Docker, Singularity or rootfs format. We intentionally support
multiple container formats as we anticipate that they will be used for
different purposes. For instance, Docker is well suited for developers
and users who manipulate applications on their local workstation. It
is well documented, maintained and it has a rich ecosystem of tools to
help build and run containers on most operating systems. Singularity
is more suited for users and platforms that need to run applications
on shared computing clusters. Bridges exist among these containers
formats to convert container images across frameworks. For instance, a
platform dedicated to high-performance computing may accept manifests
referring to Docker containers to facilitate application integration
by developers, and internally convert container images to Singularity
to run applications efficiently on clusters.

Container images are defined from their URL (Singularity and rootfs)
or name in a Docker index. Container images may specify a working
directory where the application has to be run. A hash may also be
reported to accurately identify container images and detect updates.

Containers were adopted because they allow for an automated and
lightweight integration of application implementations in
platforms. They are extremely useful to improve the reproducibility of
analyses as variations in the software environment may have an
important impact on the computed results. They also have limitations,
in particular they do not specify the hardware architecture required
to execute an application, which can be an issue in some cases.

Containers are not mandatory though. If an application manifest does
not contain any reference to a container, the platform will assume
that the application is pre-installed on the execution infrastructure. 

\subsection{Custom properties}

Custom properties may be added to the Boutiques specification without
restriction. Custom properties are corralled in a specific JSON object
to facilitate validation. They may be useful to implement
platform-specific features but they should be used with care to avoid
making applications dependent on a particular platform.

\subsection{Core tools} 

The Boutiques validator checks conformance of JSON manifests to the
Boutiques schema using a basic JSON validator. It also performs the
following checks that cannot be easily implemented in JSON schema:
value keys are unique among inputs, input and output identifiers are
unique, input and output value keys are all included in the command
line, value keys are not contained within each other (which would
puzzle substitution), output path templates are unique (to avoid
results to overwrite each other), inputs of type Flag have a
command-line flag, are optional and are not lists, number and list
constraints are sensible (e.g. min is lower than max), the default
value of enum types is part of the enum, an input cannot both require
and disable another input, required inputs cannot require or disable
other parameters, group member identifiers must correspond to existing
inputs and cannot appear in different groups, mutually exclusive
groups cannot have members requiring other members, and
one-is-required groups should never have required members. The
Boutiques validator is meant for application developers; platforms
should rely on regular JSON validation to avoid depending on a
third-party tool.

The local executor can generate and execute command line from a
Boutiques manifest and a set of input values represented in a CSV or
JSON file complying with the invocation schema. It runs the command in
a container provided that the required framework (e.g. Docker) is
already installed. It can also generate hypothetical command lines
from random values for debugging purposes. The local executor can be
used by application users to run applications locally, or by platforms
to generate command lines to be run on the execution infrastructure.

The invocation schema generator can create an invocation schema (see
Section~\ref{sec:invocation-schema}) from a \boutiques manifest and
validate input data against it using a regular JSON validator. It can
be used to add invocation schemas to existing manifests.

Finally, a JSON editor facilitates the writing of \boutiques manifests
through a web interface.

\subsection{Repository}

\todo{Gunnar, Nathaniel, John}

\section{Results}
\label{sec:results}

\subsection{Supported platforms}

The following platforms are able to integrate and execute Boutiques
applications. 

\subsubsection{CBRAIN}

CBRAIN~\cite{SHER-14} is a web platform that can process data
distributed into multiple storage locations on computing clusters and
clouds. CBRAIN offers transparent access to remote data sources,
distributed computing sites, and an array of processing and
visualization tools within a controlled, secure environment.  The
CBRAIN service deployed at the Montreal Neurological Institute relies
on the infrastructure provided by Compute Canada~\cite{das2016mni}. It
currently provides 460+ collaborators in 20 countries with web access
to several systems, including 6 clusters of the Compute Canada
high-performance computing infrastructure (totaling more than 100,000
computing cores and 40PB of disk storage) and Amazon EC2. CBRAIN
transiently stores about 10 million files representing over 50TB
distributed in 42 servers. 56 data processing applications are integrated and
over 340,000 processing batches have been submitted since 2010.

Applications in CBRAIN are integrated as Ruby classes that create web
forms, validate parameters and run command lines on computing
resources. \boutiques is supported through a set of templates that
generate such classes from the application manifest. Two application
integration modes are available:
\begin{enumerate}
  \item The manifest is stored in a CBRAIN plugin and the Ruby classes
    are generated on-the-fly when CBRAIN starts. This mode allows
    CBRAIN developers update all Boutiques applications at once by
    editing the templates. However, it does not allow for
    customization beyond the Boutiques schema.
  \item Ruby classes are generated from manifests
    through an offline process and integrated in CBRAIN as any other
    application. This mode allows developers to customize applications
    by editing the generated Ruby classes, but the resulting
    applications are difficult to maintain in the long term, in
    particular when the manifests are updated.
\end{enumerate}

A custom property (\texttt{cbrain:inherits-from-class}) was added to
the Boutiques manifest to define the Ruby class that should be used as
parent class for the application in CBRAIN. It provides more
flexibility to the first integration model described previously.

CBRAIN was also extended to support the parallelization mechanism
available in Boutiques: the CBRAIN execution agent periodically scans
the execution directories of the parallelized applications and it submits
the invocations defined in the JSON objects written by the
application in this directory.

A new list mechanism was also introduced in CBRAIN to facilitate the
iteration of Boutiques applications on large sets of files. CBRAIN
lists are specific files that contain references to other CBRAIN
files. When a list is passed to a Boutiques application, the elements
in the list are either concatenated in a single command line (when the
corresponding Boutiques input is a list), or a new command line is
generated for every element in the list (when the input is not a
list). Supporting lists as a specific CBRAIN file type allows for
improved validation. For instance, lists that contain references to
non-existent or deleted files can be detected. It also allows users to
edit lists using their own tools such as scripts or spreadsheet
applications.

\subsubsection{Flywheel}

\todo{Gunnar, Nathanael, John}

\subsubsection{Pegasus}

\todo{Rafael}

\subsubsection{SPINE}

\todo{Charles}

\subsubsection{VIP}

\todo{Sorina, Tristan}

\subsection{Ported applications}

% cbrain-plugins-neuro

Table~\ref{table:applications} summarizes the applications described
with Boutiques and the main features used.

\paragraph{Niak.} The Niak pre-processing pipeline, executed with the Pipeline System
for Octave and Matlab (PSOM)~\cite{bellec2012pipeline}, was integrated
in CBRAIN through Boutiques. The integration uses the parallelization
mechanism described in Section~\ref{sec:parallelization} so that even
the invocations processing a single subject can be parallelized. It also
allows CBRAIN to leverage the efficient agent model used in PSOM, as
described in~\cite{GLAT-16}. The integration required some work in
PSOM to facilitate its invocation as a non-interactive command-line
application. The resulting CBRAIN plugin is available at
\url{https://github.com/SIMEXP/cbrain-plugins-psom}. It could in
principle be used in other platforms that support the parallelization
property, although this has not been tested.

\paragraph{Nipype.} The Nipype workflow engine~\cite{gorgolewski2011nipype} was
instrumented to export to Boutiques applications described in its
internal Python description language. \todo{Update nipype\_cmd to
  support the latest Boutiques schema and complete this paragraph.}

\paragraph{SPM.} The Statistical Parameter Mapping toolbox (SPM)~\cite{penny2011statistical}
was exported to Boutiques \ldots \todo{Guillaume}

\paragraph{MICCAI challenges.}
Boutiques was used to integrate 23 pipelines in the VIP platform in
the context of two challenges organized by the MICCAI conference in
2016, related to the segmentation of multiple-sclerosis lesions in MR
images (MSSEG
challenge\footnote{\url{https://portal.fli-iam.irisa.fr/msseg-challenge/overview}})
and of tumor volumes in PET images (PETSEG
challenge\footnote{\url{https://portal.fli-iam.irisa.fr/petseg-challenge/overview}}). The
pipelines were ported to VIP and executed on 205 subjects in a few
weeks only, which would not have been possible without
\boutiques. Some pipelines had to be adjusted manually once ported to
the platform for the following reasons:
\begin{enumerate}
\item A pipeline
  required a GPU, which we enabled through the
  \texttt{nvidia-docker}\footnote{\url{https://github.com/NVIDIA/nvidia-docker}}
  tool not supported in Boutiques by default although it could be a possible extension.
\item A pipeline required more than 10 GB of data dependencies (atlas
  data) which exceeded the maximum size allowed for Docker containers
  in our setup. We solved the issue by installing the data in a
  directory of the host server that we mounted in the container. Such
  platform-specific configurations could not possibly be supported by
  \boutiques.
\item A pipeline wrote more than 10 GB of intermediate data in a
  temporary directory of the container located on a 2 GB partition. We
  solved the issue by mounting a host directory in the temporary directory.
\end{enumerate}
The pipelines did not use much of the expressiveness features offered
by Boutiques since the instructions given to the challengers required
that all the pipeline parameters were hardcoded, to facilitate
execution. Two custom properties (\texttt{vip:miccai-challenger-email}
and \texttt{vip:miccai-challenge-team-name}) were added to the
\boutiques manifest to help post-process results in the specific
context of MICCAI challenges.

\paragraph{Other applications.} Other neuroinformatics applications were ported to CBRAIN using Boutiques:
FSL tools and ICA AROMA are available at
\url{https://github.com/aces/cbrain-plugins-neuro} and some pipelines
of the Human Connectome Project (HCP) are at
\url{https://github.com/big-data-lab-team/cbrain-plugins-hcp}.


\todo{Chris, something on BIDS apps?}


\todo{Sorina, a paragraph on other applications in VIP?}

\begin{table}
  \begin{tabular}{l|ccccccc}
    \rowcolor[gray]{0.9}
    Application                      & \multicolumn{7}{c}{Input/Output properties} \\
    \rowcolor[gray]{0.9}
                                     & Dependencies      &Groups             & Lists             & Optional          &Default            & Enum              & Min/max\\
    
    \hline
    Niak pre-processing              &                   &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\\
    ICA AROMA                        &\cellcolor{gray!75}&\cellcolor{gray!75}&                   &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}\\
    FSL tools &&&&&&\\
    \multicolumn{1}{r|}{anat}        &\cellcolor{gray!75}&\cellcolor{gray!75}&                   &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}\\
    \multicolumn{1}{r|}{bet}         &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&                   &                   &\cellcolor{gray!75}\\      
    \multicolumn{1}{r|}{fast}        &\cellcolor{gray!75}&                   &                   &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}\\
    \multicolumn{1}{r|}{first}       &                   &                   &\cellcolor{gray!75}&\cellcolor{gray!75}&\cellcolor{gray!75}&                   &                   \\
    FSL Nipype interfaces     \\
    HCP PreFreesurfer                &                   &                   &                   &                   &                   &                   &                   \\
    MICCAI challenge (23 pipelines)\\&                   &                   &                   &                   &                   &                   & \\
    \end{tabular}
  \vspace*{0.5cm}
  \begin{tabular}{l|ccc|ccc}
    \hline
    \rowcolor[gray]{0.9}
    Application                     &\multicolumn{3}{c|}{Containers}            &  \multicolumn{3}{c}{Other properties}  \\
    \rowcolor[gray]{0.9}
                                    &Docker              & Singularity& Rootfs  & Config. file & Env vars  & Parallelization   \\
    \hline
    Niak pre-processing             &\cellcolor{gray!75} &            &         &              &\cellcolor{gray!75}&\cellcolor{gray!75}\\
    ICA AROMA                       &\cellcolor{gray!75} &            &         &              &&\\
    FSL tools &&&&&\\
    \multicolumn{1}{r|}{anat}       &                    &            &         &              &&\\
    \multicolumn{1}{r|}{bet}        &                    &            &         &              &&\\
    \multicolumn{1}{r|}{fast}       &                    &            &         &              &&\\
    \multicolumn{1}{r|}{first}      &                    &            &         &              &&\\
    FSL Nipype interfaces     \\
    HCP PreFreesurfer               &\cellcolor{gray!75} &            &         &             &&\\
    MICCAI challenge (23 pipelines) &\cellcolor{gray!75} &            &         &             &&\\
  \end{tabular} 
  \caption{Applications available in Boutiques with manifest features used.}
  \label{table:applications}
\end{table}

\section{Discussion}

With Boutiques, developers can port their application once and execute
it in several platforms. It removes the technological dependency to a
particular platform and facilitates migration.  Although the
motivating use cases were taken from neuroinformatics, our primary
field of interest, nothing prevents the system from being used in a
variety of other fields.


\subsection{\boutiques manifest}

The \boutiques manifest specification allows describing a wide range
of applications, but it is also getting increasingly complex through
additions such as invocation schemas and dependencies among inputs. In
the future, even more features might be added, for instance to allow
for a better description of when optional outputs are produced, i.e.,
which combination of input values is required. Extending the
\boutiques manifest has two main goals. First, accurately describing
application improves validation: incorrect input values and execution
results are more precisely detected when the application manifest is
comprehensive, which is essential to improve the reliability and
user-friendliness of execution platforms. Secondly, a rich manifest
schema reduces the need for custom wrappers to integrate applications
as even convoluted command lines can be described: this is
particularly interesting for applications installed in containers
since adding a wrapper to the execution stack requires an update in
the container image.

Nonetheless, a complex manifest schema has a cost for application
developers and platforms, which we address as follows. For developers,
we maintain the set of mandatory manifest properties as small as
possible so that simple applications can be described in a few lines
only (see Listing~\ref{listing:minimal}). For platforms, we aim at
supporting as many features as possible in the local executor so that
only the following steps need to be implemented to support \boutiques
in a platform, regardless of the complexity of the manifest:
\begin{enumerate}
  \item Input entry: generate the interface to allow users to enter
    input values.
  \item Input validation: create a JSON object from the interface,
    validate it against the invocation schema.
  \item Execution: generate and run the command line from the local
    executor and input JSON object.
  \item Output delivery: from the manifest, identify the output files
    and deliver them to the user.
\end{enumerate}
In particular, advanced validation features such as dependencies
between inputs are embedded in the regular JSON validation performed
at step 2, without requiring the platform to support the related
manifest properties.
\begin{listing}
\begin{minted}[frame=single,
               framesep=3mm,
               linenos=false,
               xleftmargin=21pt,
               tabsize=4]{js}
{
    "name": "echo",
    "tool-version": "1.0",
    "description": "A simple script to test output files",
    "command-line": "echo [PARAM] > output.txt",
    "schema-version": "0.4",
    "inputs": [{
	"id": "param",
	"name": "Parameter",
        "value-key": "[INPUT_FILE]",
	"type": "File"
    }],
    "output-files": [{
	"id": "output_file",
	"name": "Output file",
	"path-template": "output.txt"
    }]

}
\end{minted}
\caption{A minimal \boutiques manifest.} 
\label{listing:minimal}
\end{listing}

\subsection{Workflow support}

The parallelization framework described in~\ref{sec:parallelization}
supports workflows by considering them as both applications and
platforms, which we think is a powerful but underexploited
model. Workflows are applications because they are invoked like any
other script or executable, possibly through a command line. Workflows
are also platforms because they may invoke other applications that
might themselves be described in \boutiques. This model is powerful
because it shields the \boutiques specification from specific workflow
constructs and allows a wide range of workflow engines to be described
uniformly. 
  
\subsection{Limitations}

A few limitations remain that should be addressed in the
future. First, \boutiques moves the application porting bottleneck to
validation. Using \boutiques, functions can be automatically exported
from frameworks such as Nipype and SPM, creating hundreds of richly
described applications potentially usable by end-users. However, how
to validate that these applications actually execute as expected
remain unclear. A testing framework could be designed and potentially
fed by existing frameworks, to address this issue.

Another limitation is related to the security of containerized
applications. Since containers are usually controlled by application
developers rather than platforms, which is a good thing to reduce
application porting bottlenecks, nothing prevents developers to embed
malicious code in their container at any stage of the process,
possibly after a platform administrator inspected the
container. Containers are currently bulky file archives that are
cumbersome to inspect. Tools need to be developed to allow for an
easier characterization of container contents, for instance through
comparison digests with respect to validated base images.

% How to build modular container images for workflows.

\section{Related work}

\subsection{Common Workflow Language}

The Common Workflow Language is the closest piece of related work as
it supports containers. In particular, the Command Line Tool
Description of CWL overlaps with the \boutiques manifest. According to
Github, CWL started 6 months before Boutiques (September 2014 vs. May
2015). The differences highlighted below were identified from version
1.0 of the CWL Command Line Tool
Description\footnote{\url{http://www.commonwl.org/v1.0/CommandLineTool.html}}.

\subsubsection{Conceptual differences}

The following differences are conceptual in the sense that they may
not be easily addressed by CWL or Boutiques developers.

First, CWL has a workflow language whereas \boutiques does not. In
\boutiques, workflows are integrated as any other applications, except
that they may submit other invocations to enable workflow
parallelism. This fundamental difference has consequences on the
complexity of CWL application descriptions and on the possibility to
reuse existing workflows in \boutiques. The adoption of ontologies in
CWL may also be another consequence (see below).

CWL has a formal command-line definition while \boutiques is more
flexible. CWL specifies command lines using an array of executable and
arguments whereas \boutiques only uses a string template. \boutiques'
template approach may create issues in some cases, but it also allows
developers to add simple operations to an application without having
to write a specific wrapper. For instance, a \boutiques command line
may easily include input decompression using, e.g., the tar command in
addition to the main tool command. On the contrary, CWL applications
may only have a single executable. Importantly, \boutiques' template
system allows supporting configuration files (see
Section~\ref{sec:configuration-files}).

CWL uses ontologies while \boutiques does not. Ontologies allow for
richer definitions but they also have an overhead. The main
consequences are the following:
\begin{itemize}
\item CWL uses a specific framework for
validation, called SALAD (Semantic Annotations for Linked Avro Data)
whereas Boutiques uses plain JSON schema. The main goal of SALAD is to
allow ``working with complex data structures and document formats, such
as schemas, object references, and namespaces''. \boutiques only relies
on the basic types required to describe and validate a command line
syntactically. While the use of SALAD certainly allows for
higher-level validation, and may simplify the composition and
validation of complex workflows, it also introduces a substantial
overhead in the specification, and platforms have to use the validator
provided by CWL. On the contrary, a regular JSON validator can be used in \boutiques.
\item  CWL has a rich set of types whereas \boutiques only has simple
types. Again, this may be seen as a feature or as an overhead
depending on the context. \boutiques tries to limit the complexity of
the specification to facilitate its support by platforms where tools
will be integrated.
\end{itemize}

\subsubsection{Major differences}

The following differences are major but they may be addressed by the
CWL and \boutiques developers as they do not undermine the application
description model.

CWL tools have to write in a specific set of directories called
``designated output directory'', ``designated temporary directory''
and ``system temporary directory''. Tools are informed of the location
of such directories through environment variables. Having to write in
specific directories is problematic because tools have to be modified
to enable that. In \boutiques, the path of output files is defined
using a dedicated property.

CWL types are richer, not only
semantically but also syntactically. For instance, files have
properties for basename, dirname, location, path, checksum, etc.

\boutiques supports various types of containers (Docker, Singularity,
rootfs) while CWL supports only Docker. At the same time, CWL’s
requirements are richer: for instance, they may include RAM and disk
while Boutiques is limited to walltime estimate. CWL has hints, i.e.,
recommendations that only lead to warnings when not respected.

In \boutiques, dependencies can be defined among inputs, e.g., to
specify that an input may be used only when a particular flag is
activated. This is a very useful feature to improve validation, in
particular when tools have a lot of options.

In \boutiques, named
groups of inputs can be defined, which improves the presentation of
long parameter lists for the user and enables the definition of more
constraints within groups (e.g. mutually exclusive inputs).

\subsubsection{Other minor differences}

The \boutiques and CWL schemas have other minor differences that we
summarized in a public
spreadsheet\footnote{\url{https://docs.google.com/spreadsheets/d/1eLhpxzaaMPCIUFmV5Trs-WtaMpBO-c6QDQsmhwP7QIE/edit\#gid=0}}.

\section{Conclusion}

\boutiques is available at \url{https://github.com/boutiques}. We
welcome feedback, issue reporting and pull requests. \boutiques adopts
a bottom-up approach where new features are progressively added based
on feedback from applications and platforms. Beyond the technicalities
discussed in this paper, the availability of a solid core of
applications and platforms in the framework is key to its success,
which we plan to continuously enhance in the future.

\section{Acknowledgments}

Amazon grant.

\bibliographystyle{plain}
\bibliography{biblio}

\end{document}
